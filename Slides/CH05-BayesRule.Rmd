---
title: "ECON 4/6260 - Behaviroal Economics"
subtitle: "05 - Bayes' Rule"
author: "Dr. James Bland"


output:
  ioslides_presentation:
    widescreen: true
    smaller: true
---

<style>
.forceBreak { -webkit-column-break-after: always; break-after: column; }
</style>

```{r,include=FALSE}
knitr::opts_chunk$set(echo = FALSE,cache=T)
library(ggplot2)
library(dplyr)
set.seed(42)
```

# Bayes' rule

$$
\Pr(A \mid B)=\frac{\Pr(B \mid A)\Pr(A)}{\Pr(B)}
$$

## In comparison to Chapter 3 (risk)

**Risk:**

* I know the probabilities of events. I make my decisions bases on:
  + These probabilities
  + My preferences over events
* Core model for decision-making with risk:
  + Expected Utility Theory
  + Maximize $E[u(X)]$
  
**Beliefs:**

* How do we get those probabilities?
* If I receive new information, how should I change my beliefs?
* Do people actually do this?

## Conditional probability

> What is the probability of an event, **given that I know another event has happened**?

* What is the probability that I slip on the sidewalk given that ...
  + It is snowing?
  + It is not snowing?
  + It is snowing, and the temperature is below $10^\circ\mathrm F$?
* What is the probability that I get an exam question on Bayes' rule, given that ...
  + Dr. B only spends fifteen minutes discussing it in class
  + Dr. B spends three classes discussing it
  + Dr. B says "There will be a question on the exam on Bayes' rule"


## Example

* I roll a 6-sided die, and tell you that it is an odd number. 
  + What is the probability that I have rolled a 3?
  + What is the probability that it is a number less than or equal to 3?




... working on doc cam

We would notate these probabilities like this:
$$
\Pr(X=3 \mid X \text{ is odd}),\quad \Pr(X=3 \mid X \leq 3)
$$

## More generally

$$
\begin{aligned}
\Pr(A \cap B)&=\Pr(A \mid B) \Pr(B)\\
\Pr(\text{events A and B are both true})&=\Pr(\text{event A is true given that B is true})\Pr(\text{B is true})
\end{aligned}
$$

And we can swap the label of events $A$ and $B$, so:
$$
\begin{aligned}
\Pr(B \cap A) &=\Pr(B \mid A)\Pr(A)
\end{aligned}
$$

But the LHS of both of these expressions are the same event $(A\cap B)=(B\cap A)$, so
$$
\begin{aligned}
\Pr(A \cap B) &=\Pr(A\mid B)\Pr(B)=\Pr(B\mid A)\Pr(A)=\Pr(B \cap A)
\end{aligned}
$$
Dividing both sides of the middle equality by $\Pr(B)$:
$$
\Pr(A\mid B)=\frac{\Pr(B\mid A)\Pr(A)}{\Pr(B)}
$$

## Example from PS3 - I

```{r}

library(tidyr)
library(dplyr)
library(ggplot2)
# load the data
D<-data.frame(read.csv("../../ProblemSets/PS03Data.csv"))
P<-data.frame(read.csv("../../ProblemSets/PS03Parameters.csv"))

r<-0.2

P<-(P 
  %>% mutate(
    EVA = Aprob1*Aprize1 + Aprob2*Aprize2 + Aprob3*Aprize3,
    EVB = Bprob1*Bprize1 + Bprob2*Bprize2 + Bprob3*Bprize3,
    EUA = Aprob1*Aprize1^r + Aprob2*Aprize2^r + Aprob3*Aprize3^r,
    EUB = Bprob1*Bprize1^r + Bprob2*Bprize2^r + Bprob3*Bprize3^r)
)


P<-(P
    %>% mutate(EV_ChooseA = 1*(EVA>=EVB),EU_ChooseA = 1*(EUA>=EUB))
)

D<-(D %>% left_join(P,by="Problem.Number")
      %>% mutate(ChoseA = 1*(Decision=="a"))
    %>% filter(Round<=10)
)

knitr::kable(head(D %>% select(ID,EV_ChooseA,EU_ChooseA,ChoseA)))

```

## Example, II

```{r,echo=T}
DSum<-D %>% group_by(ID) %>% summarize(ChooseEV = sum(ChoseA==EV_ChooseA),
                                       ChooseEU = sum(ChoseA==EU_ChooseA),
                                       Count=n())
                                       
knitr::kable(DSum)
```

## Example, III

Suppose that we have the following model for decisions:

$$
\begin{aligned}
p(\text{ChooseEV}=1\mid \theta,\tau=\text{EV})&=\theta\\
p(\text{ChooseEU}=1\mid \theta,\tau=\text{EU})&=\theta\\
p(\theta)&=I(\theta\in(0,1))\quad\text{(uniform)}\\
p(\tau=\text{EU})&=\rho\\
p(\rho)&=I(\rho\in(0,1))
\end{aligned}
$$
We can write the likelihood, conditional on each type, as:
$$
p(y\mid \tau,\theta,\rho)=\theta^{y_\tau}(1-\theta)^{n-y_{\tau}}
$$
And so the overall, or "grand" likelihood is:
$$
p(y\mid \theta,\rho)=\rho \theta^{n^{EV}}(1-\theta)^{n-n_{EV}}+(1-\rho) \theta^{n^{EU}}(1-\theta)^{n-n_{EU}}
$$
and since both our priors are equal to one for values in the support, this is also (proportional to) the posterior:
$$
p(\theta,\rho\mid y)\propto\rho \theta^{n^{EV}}(1-\theta)^{n-n_{EV}}+(1-\rho) \theta^{n^{EU}}(1-\theta)^{n-n_{EU}}
$$

## Example - IV

```{r}
pgrid<-seq(0.01,0.99,length=99)


```













